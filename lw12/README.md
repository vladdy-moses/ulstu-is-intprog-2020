# Лабораторная работа №12 - Очереди сообщений

## Цель работы

Получить знания и навыки об основных системах организации обмена сообщениями в распределённых информационных системах: RebbitMQ и Apache Kafka.

## Ход работы

Представьте, что вы являетесь разработчиком сложной распределённой системы, у которой много разного API, обработчиков и баз данных.
Например, пусть это будет интернет-магазин, где есть и корзина, и список товаров, и системы биллинга, и подсистема расчёта скидок, и ещё много чего.
Весь этот "зоопарк" служб необходимо как-то координировать.
Для этого придумали понятие "сообщений", которые одна программа может в очередь положить, а другая забрать.
В нашем случае, например, сообщения могут быть:

* от подсистемы оплаты, что "товар оплачен";
* от подсистемы корзины, что "товар забронирован";
* от подсистемы склада, что "товар поступил";
* к подсистеме оплаты, что "надо оплатить товар";
* к подсистеме доставки, что "товар оплачен";
* к подсистеме склада, что "товар забронирован".

В рамках изучения материалов по этой лабораторной работе необходимо, чтобы у вас появилось понимание, как такие очереди сообщений работают, чтобы потом на настоящих крупных системах не возникало паники и мыслей [как тут](https://vk.com/fishread).

Сперва можете прочитать статью: https://habr.com/ru/company/itsumma/blog/416629/

Необходимо осознать про RabbitMQ:

* кто такие паблишеры (publishers);
* кто такое получатели (consumers);
* что такое очередь (queue);
* как сообщение попадает от паблишера до получателя;
* что значит "конкурирующие получатели";
* что такое "гарантия доставки", "гарантия хотя бы одной доставки" и "гарантия ровно одной доставки";
* что такое предел предварительной выборки (QoS);
* чем отличаются модели проталкивания (push) и выгрузки (pull) сообщений;
* как работает Topic Exchange;

Необходимо осознать про Apache Kafka:

* что такое "журнал фиксации изменений" (commit log);
* что такое топик (topic) и почему он append-only;
* что такое партиция;
* поддерживает ли партиция конкурирующих получателей и как это сделать;
* зачем вообще нужно партиционирование сообщений;
* как работает модель получения сообщений при помощи long-polling;
* как работает шаблон продюсер(издатель)/подписчик (pub/sub);
* как работает перебалансировка получателей. 

Ответы на вопросы необходимо оформить в виде отчёта с титульным листом :)
Желательно писать кратко и своими словами.

> Тонны одинаковой копипасты читать - то ещё занятие...
> Сделайте преподавателю приятно: напишите не очень много, но сами.

Следующий шаг после прочтения - усвоение материала, сиречь программирование.

Сначала необходимо установить RabbitMQ.

После этого разработать две программы:

- издатель (генератор), который каждые 100 мс создаёт и помещает в очередь сообщение;
- подписчик (обработчик), который берёт сообщение из очереди и обрабатывает его 200 мс.

Для написания приложений можно пользоваться [tutorial-ами с сайта RabbitMQ](https://www.rabbitmq.com/getstarted.html).
Также есть [переводы на хабре](https://habr.com/ru/post/149694/) (в конце статьи есть ссылка на часть 2).

При запуске одного генератора и обработчика очевидно, что сообщения в очереди будут копиться: обработка явно не поспевает за генерацией.
Это можно продемонстрировать, указывая в сообщении число по порядку (в первом сообщении 1, в следующем 2, в следующем 3, ...) и выводя его на экран в обоих программах.

При запуске ещё одного обработчика будет заметно, что сообщения генерируются и обрабатываются практически за одно время.

При запуске бОльшего числа подписчиков обработка будет происходить быстрее, чем сообщения будут попадать в очередь.

## Оформление и отправка отчёта

Титульный лист должен содержать ФИО, группу, номер работы, название.
В тексте отчёта необходимо указать цель работы и результат выполнения.
Если произошли трудности при выполнении работы, также укажите их, пожалуйста.

В отчёт необходимо добавить код программ на любом доступном языке программирования, а также скриншоты рассмотренных выше случаев (один генератор - один обработчик, один генератор - два обработчика, один генератор - три обработчика).
На скриншотах должно быть видно, какой запрос из очереди каким обработчиков взят и сколько запросов создано генератором.

После создания отчёта его необходимо преобразовать в документ pdf (в вашего покорного слуги нет MS Word, к сожалению), сохранить в облако и ссылку (проверьте её в режиме инкогнито) отправить в [эту гугл-форму](https://forms.gle/9CFJRHRE9PUBsmsF8).
